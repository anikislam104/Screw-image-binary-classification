{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten , Dropout, MaxPooling2D, Activation\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_directory = 'archive/train/'\n",
    "test_image_directory = 'archive/test/'\n",
    "size = 224\n",
    "train_images = []\n",
    "train_labels = []\n",
    "\n",
    "good_train_images = os.listdir(train_image_directory + 'good/')\n",
    "\n",
    "for i,image_name in enumerate(good_train_images):\n",
    "    image = cv2.imread(train_image_directory + 'good/' + image_name)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  \n",
    "    image = cv2.resize(image, (size, size))  \n",
    "    image = np.array(image)\n",
    "    train_images.append(image)\n",
    "    train_labels.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_train_images = os.listdir(train_image_directory + 'not-good/')\n",
    "for i,image_name in enumerate(bad_train_images):\n",
    "    image = cv2.imread(train_image_directory + 'not-good/' + image_name)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (size, size))\n",
    "    image = np.array(image)\n",
    "    train_images.append(image)\n",
    "    train_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 224, 224, 3)\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.astype('float32') / 255.0\n",
    "train_images = (train_images - np.mean(train_images)) / np.std(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "test_images = []\n",
    "\n",
    "test_images_dir = os.listdir(test_image_directory)\n",
    "for i,image_name in enumerate(test_images_dir):\n",
    "    image = cv2.imread(test_image_directory + image_name)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (size, size))\n",
    "    image = np.array(image)\n",
    "    test_images.append(image)\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "print(test_images.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "input_shape = (size, size, 3)\n",
    "\n",
    "model.add(Conv2D(filters=96, input_shape=input_shape, kernel_size=(11,11), strides=(4,4), padding='valid', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, input_shape=(224*224*3,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1000))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 54, 54, 96)        34944     \n",
      "                                                                 \n",
      " activation (Activation)     (None, 54, 54, 96)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 27, 27, 96)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 17, 17, 256)       2973952   \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 17, 17, 256)       0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 6, 6, 384)         885120    \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 6, 6, 384)         0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 6, 6, 384)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 13824)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              56627200  \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1000)              4097000   \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 1001      \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 81,400,529\n",
      "Trainable params: 81,400,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and validation set split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_images, train_labels, test_size=0.15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 15s 2s/step - loss: 2.0016 - accuracy: 0.7882 - val_loss: 1.6869 - val_accuracy: 0.9333\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 12s 2s/step - loss: 1.8116 - accuracy: 0.8157 - val_loss: 1.6041 - val_accuracy: 0.9333\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 12s 1s/step - loss: 1.6915 - accuracy: 0.8157 - val_loss: 1.5187 - val_accuracy: 0.9333\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 13s 2s/step - loss: 1.5743 - accuracy: 0.8157 - val_loss: 1.3401 - val_accuracy: 0.9333\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 12s 2s/step - loss: 1.4845 - accuracy: 0.8157 - val_loss: 1.2078 - val_accuracy: 0.9333\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 12s 2s/step - loss: 1.3952 - accuracy: 0.8157 - val_loss: 1.2913 - val_accuracy: 0.9333\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 13s 2s/step - loss: 1.3001 - accuracy: 0.8157 - val_loss: 1.0865 - val_accuracy: 0.9333\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 13s 2s/step - loss: 1.2171 - accuracy: 0.8157 - val_loss: 1.0064 - val_accuracy: 0.9333\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 12s 2s/step - loss: 1.1668 - accuracy: 0.8157 - val_loss: 0.9116 - val_accuracy: 0.9333\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 13s 2s/step - loss: 1.0937 - accuracy: 0.8157 - val_loss: 0.9343 - val_accuracy: 0.9333\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction on Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 2s 263ms/step\n"
     ]
    }
   ],
   "source": [
    "# predict on test images\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions(predictions):\n",
    "    predictions = 1/(1+np.exp(-predictions))\n",
    "    predictions = (predictions - predictions.min())/(predictions.max() - predictions.min())\n",
    "    new_predictions = []\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] <= predictions.mean():\n",
    "            new_predictions.append(\"test_\" + str(i) + \" good\")\n",
    "        else:\n",
    "            new_predictions.append(\"test_\" + str(i) + \" not-good\")\n",
    "    return new_predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniki\\AppData\\Local\\Temp/ipykernel_12088/423631186.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions = (predictions - predictions.min())/(predictions.max() - predictions.min())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['test_0 not-good',\n",
       " 'test_1 not-good',\n",
       " 'test_2 not-good',\n",
       " 'test_3 not-good',\n",
       " 'test_4 not-good',\n",
       " 'test_5 not-good',\n",
       " 'test_6 not-good',\n",
       " 'test_7 not-good',\n",
       " 'test_8 not-good',\n",
       " 'test_9 not-good',\n",
       " 'test_10 not-good',\n",
       " 'test_11 not-good',\n",
       " 'test_12 not-good',\n",
       " 'test_13 not-good',\n",
       " 'test_14 not-good',\n",
       " 'test_15 not-good',\n",
       " 'test_16 not-good',\n",
       " 'test_17 not-good',\n",
       " 'test_18 not-good',\n",
       " 'test_19 not-good',\n",
       " 'test_20 not-good',\n",
       " 'test_21 not-good',\n",
       " 'test_22 not-good',\n",
       " 'test_23 not-good',\n",
       " 'test_24 not-good',\n",
       " 'test_25 not-good',\n",
       " 'test_26 not-good',\n",
       " 'test_27 not-good',\n",
       " 'test_28 not-good',\n",
       " 'test_29 not-good',\n",
       " 'test_30 not-good',\n",
       " 'test_31 not-good',\n",
       " 'test_32 not-good',\n",
       " 'test_33 not-good',\n",
       " 'test_34 not-good',\n",
       " 'test_35 not-good',\n",
       " 'test_36 not-good',\n",
       " 'test_37 not-good',\n",
       " 'test_38 not-good',\n",
       " 'test_39 not-good',\n",
       " 'test_40 not-good',\n",
       " 'test_41 not-good',\n",
       " 'test_42 not-good',\n",
       " 'test_43 not-good',\n",
       " 'test_44 not-good',\n",
       " 'test_45 not-good',\n",
       " 'test_46 not-good',\n",
       " 'test_47 not-good',\n",
       " 'test_48 not-good',\n",
       " 'test_49 not-good',\n",
       " 'test_50 not-good',\n",
       " 'test_51 not-good',\n",
       " 'test_52 not-good',\n",
       " 'test_53 not-good',\n",
       " 'test_54 not-good',\n",
       " 'test_55 not-good',\n",
       " 'test_56 not-good',\n",
       " 'test_57 not-good',\n",
       " 'test_58 not-good',\n",
       " 'test_59 not-good',\n",
       " 'test_60 not-good',\n",
       " 'test_61 not-good',\n",
       " 'test_62 not-good',\n",
       " 'test_63 not-good',\n",
       " 'test_64 not-good',\n",
       " 'test_65 not-good',\n",
       " 'test_66 not-good',\n",
       " 'test_67 not-good',\n",
       " 'test_68 not-good',\n",
       " 'test_69 not-good',\n",
       " 'test_70 not-good',\n",
       " 'test_71 not-good',\n",
       " 'test_72 not-good',\n",
       " 'test_73 not-good',\n",
       " 'test_74 not-good',\n",
       " 'test_75 not-good',\n",
       " 'test_76 not-good',\n",
       " 'test_77 not-good',\n",
       " 'test_78 not-good',\n",
       " 'test_79 not-good',\n",
       " 'test_80 not-good',\n",
       " 'test_81 not-good',\n",
       " 'test_82 not-good',\n",
       " 'test_83 not-good',\n",
       " 'test_84 not-good',\n",
       " 'test_85 not-good',\n",
       " 'test_86 not-good',\n",
       " 'test_87 not-good',\n",
       " 'test_88 not-good',\n",
       " 'test_89 not-good',\n",
       " 'test_90 not-good',\n",
       " 'test_91 not-good',\n",
       " 'test_92 not-good',\n",
       " 'test_93 not-good',\n",
       " 'test_94 not-good',\n",
       " 'test_95 not-good',\n",
       " 'test_96 not-good',\n",
       " 'test_97 not-good',\n",
       " 'test_98 not-good',\n",
       " 'test_99 not-good',\n",
       " 'test_100 not-good',\n",
       " 'test_101 not-good',\n",
       " 'test_102 not-good',\n",
       " 'test_103 not-good',\n",
       " 'test_104 not-good',\n",
       " 'test_105 not-good',\n",
       " 'test_106 not-good',\n",
       " 'test_107 not-good',\n",
       " 'test_108 not-good',\n",
       " 'test_109 not-good',\n",
       " 'test_110 not-good',\n",
       " 'test_111 not-good',\n",
       " 'test_112 not-good',\n",
       " 'test_113 not-good',\n",
       " 'test_114 not-good',\n",
       " 'test_115 not-good',\n",
       " 'test_116 not-good',\n",
       " 'test_117 not-good',\n",
       " 'test_118 not-good',\n",
       " 'test_119 not-good',\n",
       " 'test_120 not-good',\n",
       " 'test_121 not-good',\n",
       " 'test_122 not-good',\n",
       " 'test_123 not-good',\n",
       " 'test_124 not-good',\n",
       " 'test_125 not-good',\n",
       " 'test_126 not-good',\n",
       " 'test_127 not-good',\n",
       " 'test_128 not-good',\n",
       " 'test_129 not-good',\n",
       " 'test_130 not-good',\n",
       " 'test_131 not-good',\n",
       " 'test_132 not-good',\n",
       " 'test_133 not-good',\n",
       " 'test_134 not-good',\n",
       " 'test_135 not-good',\n",
       " 'test_136 not-good',\n",
       " 'test_137 not-good',\n",
       " 'test_138 not-good',\n",
       " 'test_139 not-good',\n",
       " 'test_140 not-good',\n",
       " 'test_141 not-good',\n",
       " 'test_142 not-good',\n",
       " 'test_143 not-good',\n",
       " 'test_144 not-good',\n",
       " 'test_145 not-good',\n",
       " 'test_146 not-good',\n",
       " 'test_147 not-good',\n",
       " 'test_148 not-good',\n",
       " 'test_149 not-good',\n",
       " 'test_150 not-good',\n",
       " 'test_151 not-good',\n",
       " 'test_152 not-good',\n",
       " 'test_153 not-good',\n",
       " 'test_154 not-good',\n",
       " 'test_155 not-good',\n",
       " 'test_156 not-good',\n",
       " 'test_157 not-good',\n",
       " 'test_158 not-good',\n",
       " 'test_159 not-good',\n",
       " 'test_160 not-good',\n",
       " 'test_161 not-good',\n",
       " 'test_162 not-good',\n",
       " 'test_163 not-good',\n",
       " 'test_164 not-good',\n",
       " 'test_165 not-good',\n",
       " 'test_166 not-good',\n",
       " 'test_167 not-good',\n",
       " 'test_168 not-good',\n",
       " 'test_169 not-good',\n",
       " 'test_170 not-good',\n",
       " 'test_171 not-good',\n",
       " 'test_172 not-good',\n",
       " 'test_173 not-good',\n",
       " 'test_174 not-good',\n",
       " 'test_175 not-good',\n",
       " 'test_176 not-good',\n",
       " 'test_177 not-good',\n",
       " 'test_178 not-good',\n",
       " 'test_179 not-good']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_predictions(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
